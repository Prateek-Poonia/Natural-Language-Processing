{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP87i7vxzR52D7Vdr9JI+U3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prateek-Poonia/Natural-Language-Processing/blob/main/Lemmatization_Bag_of_words_TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k-NqjpTfs_gR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f616ef-6185-4cef-8352-d7c19d780060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation, NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike. NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.\""
      ],
      "metadata": {
        "id": "pjCHDBuWt4dj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "icbSddyRt9jw",
        "outputId": "48801fc9-2f73-4ecd-8190-163dcf6f9958"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation, NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike. NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "o44Pt0zkt-YJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization --> converts paragraph -sentences-words\n",
        "nltk.download('punkt')\n",
        "sentences = nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7KdgPycuJSd",
        "outputId": "c66d6be8-8e03-4844-da4f-958b39cec117"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDeLKRQgujvu",
        "outputId": "562b83bc-3efe-47c2-8c1c-ae286175f2f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLTK is a leading platform for building Python programs to work with human language data.',\n",
              " 'It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation, NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.',\n",
              " 'NLTK is available for Windows, Mac OS X, and Linux.',\n",
              " 'Best of all, NLTK is a free, open source, community-driven project.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " type(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAdzzCK8uoDY",
        "outputId": "9a93bdb1-758e-4f67-dfe8-42287ed69eda"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming\n",
        "stemmer=PorterStemmer()\n"
      ],
      "metadata": {
        "id": "7jO1ppzd3pY5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('programming')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pWh-Csma4GLA",
        "outputId": "f29259f5-2e00-4099-b49d-e45ebf6ff4d6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'program'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "Ig9ftU7P4Mic"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "jiRMc-Qa5Ww0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgB8qdX14Xok",
        "outputId": "790aa120-3206-4a3f-9151-dbf160ce2bab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('reasoning')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mNuKO5tm4aMV",
        "outputId": "26af0749-89ca-4f44-af4b-1b93ccd33d90"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'reasoning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "IMW2mtVf4h5L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRHPIWqD5w1s",
        "outputId": "663fc4e8-89a7-49b4-b1d0-f6b62ae7c23c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=[]\n",
        "for i in range(len(sentences)):\n",
        "  review=re.sub('[^a-zA-Z]',' ',sentences[i])\n",
        "  review=review.lower()\n",
        "  corpus.append(review)"
      ],
      "metadata": {
        "id": "ifNPWjpK4rDY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmAOVQI54xct",
        "outputId": "48816b8b-6793-482c-f253-151071b74cbe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nltk is a leading platform for building python programs to work with human language data ',\n",
              " 'it provides easy to use interfaces to over    corpora and lexical resources such as wordnet  along with a suite of text processing libraries for classification  tokenization  stemming  tagging  parsing  and semantic reasoning  wrappers for industrial strength nlp libraries  and an active discussion forum thanks to a hands on guide introducing programming fundamentals alongside topics in computational linguistics  plus comprehensive api documentation  nltk is suitable for linguists  engineers  students  educators  researchers  and industry users alike ',\n",
              " 'nltk is available for windows  mac os x  and linux ',\n",
              " 'best of all  nltk is a free  open source  community driven project ']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElqRJNL77SKP",
        "outputId": "c06bbbcb-40e3-41c5-d95c-732d66a3e520"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stemming\n",
        "for i in corpus:\n",
        "  words = nltk.word_tokenize(i)\n",
        "  for word in words:\n",
        "    if word not in set(stopwords.words('english')):\n",
        "      print(stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKprVCl56htv",
        "outputId": "868fe277-c1e6-4567-cec6-59f342e51e0d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nltk\n",
            "lead\n",
            "platform\n",
            "build\n",
            "python\n",
            "program\n",
            "work\n",
            "human\n",
            "languag\n",
            "data\n",
            "provid\n",
            "easi\n",
            "use\n",
            "interfac\n",
            "corpora\n",
            "lexic\n",
            "resourc\n",
            "wordnet\n",
            "along\n",
            "suit\n",
            "text\n",
            "process\n",
            "librari\n",
            "classif\n",
            "token\n",
            "stem\n",
            "tag\n",
            "pars\n",
            "semant\n",
            "reason\n",
            "wrapper\n",
            "industri\n",
            "strength\n",
            "nlp\n",
            "librari\n",
            "activ\n",
            "discuss\n",
            "forum\n",
            "thank\n",
            "hand\n",
            "guid\n",
            "introduc\n",
            "program\n",
            "fundament\n",
            "alongsid\n",
            "topic\n",
            "comput\n",
            "linguist\n",
            "plu\n",
            "comprehens\n",
            "api\n",
            "document\n",
            "nltk\n",
            "suitabl\n",
            "linguist\n",
            "engin\n",
            "student\n",
            "educ\n",
            "research\n",
            "industri\n",
            "user\n",
            "alik\n",
            "nltk\n",
            "avail\n",
            "window\n",
            "mac\n",
            "os\n",
            "x\n",
            "linux\n",
            "best\n",
            "nltk\n",
            "free\n",
            "open\n",
            "sourc\n",
            "commun\n",
            "driven\n",
            "project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatization\n",
        "for i in corpus:\n",
        "  words = nltk.word_tokenize(i)\n",
        "  for word in words:\n",
        "    if word not in set(stopwords.words('english')):\n",
        "      print(lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiE-sq5d6uMh",
        "outputId": "7ab449aa-9235-4820-fd81-8e994080fac9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nltk\n",
            "leading\n",
            "platform\n",
            "building\n",
            "python\n",
            "program\n",
            "work\n",
            "human\n",
            "language\n",
            "data\n",
            "provides\n",
            "easy\n",
            "use\n",
            "interface\n",
            "corpus\n",
            "lexical\n",
            "resource\n",
            "wordnet\n",
            "along\n",
            "suite\n",
            "text\n",
            "processing\n",
            "library\n",
            "classification\n",
            "tokenization\n",
            "stemming\n",
            "tagging\n",
            "parsing\n",
            "semantic\n",
            "reasoning\n",
            "wrapper\n",
            "industrial\n",
            "strength\n",
            "nlp\n",
            "library\n",
            "active\n",
            "discussion\n",
            "forum\n",
            "thanks\n",
            "hand\n",
            "guide\n",
            "introducing\n",
            "programming\n",
            "fundamental\n",
            "alongside\n",
            "topic\n",
            "computational\n",
            "linguistics\n",
            "plus\n",
            "comprehensive\n",
            "api\n",
            "documentation\n",
            "nltk\n",
            "suitable\n",
            "linguist\n",
            "engineer\n",
            "student\n",
            "educator\n",
            "researcher\n",
            "industry\n",
            "user\n",
            "alike\n",
            "nltk\n",
            "available\n",
            "window\n",
            "mac\n",
            "o\n",
            "x\n",
            "linux\n",
            "best\n",
            "nltk\n",
            "free\n",
            "open\n",
            "source\n",
            "community\n",
            "driven\n",
            "project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply stopwords lemmatize\n",
        "import re\n",
        "corpus=[]\n",
        "for i in range(len(sentences)):\n",
        "  review=re.sub('[^a-zA-Z]',' ',sentences[i])\n",
        "  review=review.lower()\n",
        "  review=review.split()\n",
        "  review=[lemmatizer.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "  review=' '.join(review)\n",
        "  corpus.append(review)"
      ],
      "metadata": {
        "id": "lehji9Cl9mxJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Bag of words\n",
        " from sklearn.feature_extraction.text import CountVectorizer\n",
        " cv = CountVectorizer(binary=True,ngram_range=(3,3))\n"
      ],
      "metadata": {
        "id": "-bH1mEiT7qex"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " X = cv.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "PFHNkElz7_B3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAcRRqfw7_82",
        "outputId": "d64e4f47-71ad-472e-b5e5-cf2b911f3ad6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nltk leading platform': 36,\n",
              " 'leading platform building': 27,\n",
              " 'platform building python': 40,\n",
              " 'building python program': 6,\n",
              " 'python program work': 46,\n",
              " 'program work human': 43,\n",
              " 'work human language': 65,\n",
              " 'human language data': 22,\n",
              " 'provides easy use': 45,\n",
              " 'easy use interface': 14,\n",
              " 'use interface corpus': 62,\n",
              " 'interface corpus lexical': 25,\n",
              " 'corpus lexical resource': 11,\n",
              " 'lexical resource wordnet': 28,\n",
              " 'resource wordnet along': 49,\n",
              " 'wordnet along suite': 64,\n",
              " 'along suite text': 1,\n",
              " 'suite text processing': 56,\n",
              " 'text processing library': 58,\n",
              " 'processing library classification': 42,\n",
              " 'library classification tokenization': 30,\n",
              " 'classification tokenization stemming': 7,\n",
              " 'tokenization stemming tagging': 60,\n",
              " 'stemming tagging parsing': 52,\n",
              " 'tagging parsing semantic': 57,\n",
              " 'parsing semantic reasoning': 39,\n",
              " 'semantic reasoning wrapper': 50,\n",
              " 'reasoning wrapper industrial': 47,\n",
              " 'wrapper industrial strength': 66,\n",
              " 'industrial strength nlp': 23,\n",
              " 'strength nlp library': 53,\n",
              " 'nlp library active': 33,\n",
              " 'library active discussion': 29,\n",
              " 'active discussion forum': 0,\n",
              " 'discussion forum thanks': 12,\n",
              " 'forum thanks hand': 17,\n",
              " 'thanks hand guide': 59,\n",
              " 'hand guide introducing': 21,\n",
              " 'guide introducing programming': 20,\n",
              " 'introducing programming fundamental': 26,\n",
              " 'programming fundamental alongside': 44,\n",
              " 'fundamental alongside topic': 19,\n",
              " 'alongside topic computational': 2,\n",
              " 'topic computational linguistics': 61,\n",
              " 'computational linguistics plus': 10,\n",
              " 'linguistics plus comprehensive': 32,\n",
              " 'plus comprehensive api': 41,\n",
              " 'comprehensive api documentation': 9,\n",
              " 'api documentation nltk': 3,\n",
              " 'documentation nltk suitable': 13,\n",
              " 'nltk suitable linguist': 37,\n",
              " 'suitable linguist engineer': 55,\n",
              " 'linguist engineer student': 31,\n",
              " 'engineer student educator': 16,\n",
              " 'student educator researcher': 54,\n",
              " 'educator researcher industry': 15,\n",
              " 'researcher industry user': 48,\n",
              " 'industry user alike': 24,\n",
              " 'nltk available window': 34,\n",
              " 'available window mac': 4,\n",
              " 'window mac linux': 63,\n",
              " 'best nltk free': 5,\n",
              " 'nltk free open': 35,\n",
              " 'free open source': 18,\n",
              " 'open source community': 38,\n",
              " 'source community driven': 51,\n",
              " 'community driven project': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gF37kYoD8A7T",
        "outputId": "1efac498-b8f5-4a6c-c5ba-c858f2170c5c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nltk leading platform building python program work human language data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DGBX-Yn8LJc",
        "outputId": "ba9198c6-15c4-4c39-ae42-61a87d4538c5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF_IDF\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "cv = TfidfVectorizer()\n",
        "X = cv.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "phAEcW-m8OXB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KWKHf1nc_4hS",
        "outputId": "59aed80c-638b-4790-f8e0-ebd913364fb2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nltk leading platform building python program work human language data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdyRoR8h_8Ey",
        "outputId": "b76a6f72-42cd-4492-cbe7-a6e38aac0bda"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.32840203, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.32840203, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.32840203, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.32840203, 0.32840203, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.1713738 ,\n",
              "        0.        , 0.        , 0.32840203, 0.        , 0.        ,\n",
              "        0.32840203, 0.        , 0.        , 0.        , 0.32840203,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.32840203,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4DDos0Bn_9ar"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}